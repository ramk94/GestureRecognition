{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainer",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramk94/GestureRecognition/blob/master/trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eIN1HAeJnxs",
        "colab_type": "text"
      },
      "source": [
        "***Check the Version of Tensor Flow***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFY3YA1GJQWU",
        "colab_type": "code",
        "outputId": "42ee7fc5-b2af-42fd-d49b-c94694aa0913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svsrGowZHK-f",
        "colab_type": "text"
      },
      "source": [
        "**Upload the zip file of the images and unizip it following the command**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv-LDQM2rDzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip Archive.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka_Ey23vGc1T",
        "colab_type": "text"
      },
      "source": [
        "**Import Librariers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObcrJxQ9rdYB",
        "colab_type": "code",
        "outputId": "1a7d89e7-d6a5-49e2-9c91-c5a36845120f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d,max_pool_2d\n",
        "from tflearn.layers.core import input_data,dropout,fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEsO_XY-GkWR",
        "colab_type": "text"
      },
      "source": [
        "**Load Images and put it in a vector**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o62T5gqY0ao_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loadedImages = []\n",
        "\n",
        "#Load Images From Fist\n",
        "for i in range(0, 1000):\n",
        "    image = cv2.imread('fist/fist_' + str(i) + '.png')\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    loadedImages.append(gray_image.reshape(89, 100, 1))\n",
        "    \n",
        "#Load Images from Palm\n",
        "for i in range(0, 1000):\n",
        "    image = cv2.imread('palm/palm_' + str(i) + '.png')\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    loadedImages.append(gray_image.reshape(89, 100, 1))\n",
        "    \n",
        "#Load Images from Swing\n",
        "for i in range(0, 1000):\n",
        "    image = cv2.imread('swing/swing_' + str(i) + '.png')\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    loadedImages.append(gray_image.reshape(89, 100, 1))\n",
        "\n",
        "#Load Images From Peace\n",
        "for i in range(0, 1000):\n",
        "    image = cv2.imread('peace/peace_' + str(i) + '.png')\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    loadedImages.append(gray_image.reshape(89, 100, 1))\n",
        "    \n",
        "\n",
        "#Load Images From None\n",
        "for i in range(0, 1000):\n",
        "    image = cv2.imread('NONE/NONE_' + str(i) + '.png')\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    loadedImages.append(gray_image.reshape(89, 100, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKN-Wrs0GtjZ",
        "colab_type": "text"
      },
      "source": [
        "**Create the output vector with four values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU_2hrQ84PfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create OutputVector\n",
        "\n",
        "outputVectors = []\n",
        "for i in range(0, 1000):\n",
        "    outputVectors.append([1, 0, 0,0,0])\n",
        "\n",
        "for i in range(0, 1000):\n",
        "    outputVectors.append([0, 1, 0,0,0])\n",
        "\n",
        "for i in range(0, 1000):\n",
        "    outputVectors.append([0, 0, 1,0,0])\n",
        "    \n",
        "for i in range(0, 1000):\n",
        "    outputVectors.append([0, 0, 0,1,0])\n",
        "\n",
        "for i in range(0, 1000):\n",
        "    outputVectors.append([0, 0, 0,0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twdFQQKiG1GV",
        "colab_type": "text"
      },
      "source": [
        "**Load the test Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxdpxE5F4R-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testImages = []\n",
        "\n",
        "#Load Images for Fist\n",
        "for i in range(0, 100):\n",
        "    image = cv2.imread('fist_test/fist_' + str(i) + '.png')\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    testImages.append(gray_image.reshape(89, 100, 1))\n",
        "    \n",
        "#Load Images for Palm\n",
        "for i in range(0, 100):\n",
        "    image = cv2.imread('palm_test/palm_' + str(i) + '.png')\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    testImages.append(gray_image.reshape(89, 100, 1))\n",
        "    \n",
        "#Load Images for Swing\n",
        "for i in range(0, 100):\n",
        "    image = cv2.imread('swing_test/swing_' + str(i) + '.png')\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    testImages.append(gray_image.reshape(89, 100, 1))\n",
        "\n",
        "#Load Images for Peace\n",
        "for i in range(0, 100):\n",
        "    image = cv2.imread('peace_test/peace_' + str(i) + '.png')\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    testImages.append(gray_image.reshape(89, 100, 1))\n",
        "    \n",
        "#Load Images for None\n",
        "for i in range(0, 100):\n",
        "    image = cv2.imread('NONETEST/NONE_' + str(i) + '.png')\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    testImages.append(gray_image.reshape(89, 100, 1))\n",
        "\n",
        "\n",
        "#Labes for the test vector\n",
        "\n",
        "testLabels = []\n",
        "\n",
        "for i in range(0, 100):\n",
        "    testLabels.append([1, 0, 0,0,0])\n",
        "    \n",
        "for i in range(0, 100):\n",
        "    testLabels.append([0, 1, 0,0,0])\n",
        "\n",
        "for i in range(0, 100):\n",
        "    testLabels.append([0, 0, 1,0,0])\n",
        "    \n",
        "for i in range(0, 100):\n",
        "    testLabels.append([0, 0, 0,1,0])\n",
        "    \n",
        "for i in range(0, 100):\n",
        "    testLabels.append([0, 0, 0,0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IujtWYH5xRNH",
        "colab_type": "text"
      },
      "source": [
        "stride is the number of units the filter shifts each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvQFrQmV4hRH",
        "colab_type": "code",
        "outputId": "a03066f6-6d2d-4645-8e91-3d85bb0f73ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# Define the CNN Model\n",
        "tf.reset_default_graph()\n",
        "convnet=input_data(shape=[None,89,100,1],name='input')\n",
        "#32 Filters, 2 Stride, Activation is relu\n",
        "convnet=conv_2d(convnet,32,2,activation='relu')\n",
        "convnet=max_pool_2d(convnet,2)\n",
        "\n",
        "convnet=conv_2d(convnet,64,2,activation='relu')\n",
        "convnet=max_pool_2d(convnet,2)\n",
        "\n",
        "convnet=conv_2d(convnet,128,2,activation='relu')\n",
        "convnet=max_pool_2d(convnet,2)\n",
        "\n",
        "convnet=conv_2d(convnet,256,2,activation='relu')\n",
        "convnet=max_pool_2d(convnet,2)\n",
        "\n",
        "convnet=conv_2d(convnet,256,2,activation='relu')\n",
        "convnet=max_pool_2d(convnet,2)\n",
        "\n",
        "convnet=conv_2d(convnet,128,2,activation='relu')\n",
        "convnet=max_pool_2d(convnet,2)\n",
        "\n",
        "convnet=conv_2d(convnet,64,2,activation='relu')\n",
        "convnet=max_pool_2d(convnet,2)\n",
        "\n",
        "convnet=fully_connected(convnet,1000,activation='relu')\n",
        "convnet=dropout(convnet,0.75)\n",
        "\n",
        "convnet=fully_connected(convnet,5,activation='softmax')\n",
        "\n",
        "convnet=regression(convnet,optimizer='adam',learning_rate=0.001,loss='categorical_crossentropy',name='regression')\n",
        "\n",
        "model=tflearn.DNN(convnet,tensorboard_verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/layers/core.py:239: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgm5wWQ5HCWV",
        "colab_type": "text"
      },
      "source": [
        "**Train the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyzzDqkl4u3r",
        "colab_type": "code",
        "outputId": "815b270c-390b-4182-b0c6-85ef19b8f72a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Shuffle Training Data\n",
        "loadedImages, outputVectors = shuffle(loadedImages, outputVectors, random_state=0)\n",
        "\n",
        "# Train model\n",
        "model.fit(loadedImages, outputVectors, n_epoch=50,\n",
        "           validation_set = (testImages, testLabels),\n",
        "           snapshot_step=100, show_metric=True, run_id='convnet_coursera')\n",
        "\n",
        "model.save(\"TrainedModel/GestureRecogModel.tfl\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 3949  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 2.855s\n",
            "| Adam | epoch: 050 | loss: 0.00000 - acc: 1.0000 -- iter: 4992/5000\n",
            "Training Step: 3950  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 3.881s\n",
            "| Adam | epoch: 050 | loss: 0.00000 - acc: 1.0000 | val_loss: 0.55160 - val_acc: 0.9660 -- iter: 5000/5000\n",
            "--\n",
            "INFO:tensorflow:/content/TrainedModel/GestureRecogModel.tfl is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}